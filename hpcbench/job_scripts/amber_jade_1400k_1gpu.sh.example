#!/bin/bash
#SBATCH --nodes=1
#SBATCH --time=00:30:00
#SBATCH --job-name=amb_1gpu_140ka
#SBATCH --gres=gpu:1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mail-type=NONE
#SBATCH --mail-user=robert.welch@stfc.ac.uk
#SBATCH --partition=devel

# NOTE: this does not scale to multiple GPUs OR with MPI because CUDA and MPI on jade2 are totally scuffed

set -e

module load amber
export PATH="/jmain02/home/J2AD004/sxk40/rxw76-sxk40/anaconda3/bin:$PATH"

hpcbench infolog sysinfo.json
#hpcbench syslog -s /sys/class/hwmon/hwmon3/device/power1_average:power:1 -s /sys/class/hwmon/hwmon4/temp1_input:temp:0.001 syslog.json
hpcbench gpulog gpulog.json & gpuid=$!
hpcbench cpulog "'pmemd.cuda'" cpulog.json & cpuid=$!


pmemd.cuda -O -i benchmark.in -p benchmark.top -c benchmark.rst -ref benchmark.rst -o benchmark.mdout -r benchmark2.rst -x benchmark.nc

kill $gpuid
kill $cpuid

hpcbench amberlog benchmark.mdout amber.json
hpcbench slurmlog jade_amber_1400k_1gpu.sh slurm.json
hpcbench extra -e "'Comment:example run'" -e "'Machine:JADE'" meta.json
hpcbench collate -l sysinfo.json gpulog.json cpulog.json amber.json slurm.json meta.json -o jade_amber_1400k_1gpu.json
